---
title:                "Завантаження веб-сторінки"
html_title:           "Bash: Завантаження веб-сторінки"
simple_title:         "Завантаження веб-сторінки"
programming_language: "Bash"
category:             "Bash"
tag:                  "HTML and the Web"
editURL:              "https://github.com/dogweather/forkful/blob/master/content/uk/bash/downloading-a-web-page.md"
---

{{< edit_this_page >}}

## Що & Чому?
Скачування веб-сторінки це коли ваш комп'ютер "тягне" інформацію з інтернету і зберігає її на вашому жорсткому диску. Програмісти часто роблять це для отримання даних, які потім можна обробити або використовувати для своїх проектів.

## Як:
Завантаження веб-сторінки можна виконати за допомогою команди ```curl <URL>``` у терміналі. Це дозволяє отримати всі дані з вказаної адреси і зберегти їх в файл або вивести на екран. Наприклад, команда ```curl www.example.com``` виведе HTML код сторінки ```www.example.com``` на екран.

## Глибока погрузка:
Команда ```curl``` стала популярною з появою інтернету. До цього, програмісти використовували інші методи, такі як FTP або Telnet для скачування веб-сторінок. Існують альтернативи для ```curl```, такі як ```wget```, проте ```curl``` має більш широку функціональність та підтримку. Ця команда також може виконувати запити до серверів, пересилати дані та автоматично обробляти перенаправлення.

## Дивись також:
Якщо ви хочете дізнатися більше про команду ```curl```, можете ознайомитися з документацією на офіційному сайті (https://curl.haxx.se/docs/). Там ви знайдете багато прикладів використання та деталізовану інформацію про кожен параметр. Також існують інші корисні ресурси, які можуть допомогти вам з роботою з командою ```curl```.

Наприклад, на сайті Stack Overflow (https://stackoverflow.com/) знайдете багато запитань та відповідей про використання ```curl```, а на YouTube можна знайти відеоуроки та демонстрації цієї команди (наприклад, https://www.youtube.com/watch?v=DgRrx5_lZmI).

Не бійтеся експериментувати та використовувати ```curl``` у своїх проектах, адже це потужний інструмент для отримання даних з інтернету.