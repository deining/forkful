---
changelog:
- 2024-02-03, gpt-4-0125-preview, translated from English
date: 2024-02-03 19:13:25.180638-07:00
description: "\u0915\u0948\u0938\u0947: \u092B\u093F\u0936 \u0936\u0947\u0932 \u092E\
  \u0941\u0916\u094D\u092F \u0930\u0942\u092A \u0938\u0947 HTML \u0915\u094B \u0938\
  \u0940\u0927\u0947 \u092A\u093E\u0930\u094D\u0938 \u0915\u0930\u0928\u0947 \u0915\
  \u0947 \u0932\u093F\u090F \u0928\u0939\u0940\u0902 \u092C\u0928\u093E\u092F\u093E\
  \ \u0917\u092F\u093E \u0939\u0948\u0964 \u0939\u093E\u0932\u093E\u0901\u0915\u093F\
  , \u092F\u0939 `curl`, `grep`, `sed`, `awk` \u091C\u0948\u0938\u0947 Unix \u0914\
  \u091C\u093E\u0930\u094B\u0902 \u0915\u094B \u090F\u0915 \u0938\u093E\u0925 \u091C\
  \u094B\u0921\u093C\u0928\u0947 \u092F\u093E\u2026"
lastmod: '2024-03-13T22:44:53.062508-06:00'
model: gpt-4-0125-preview
summary: "\u092B\u093F\u0936 \u0936\u0947\u0932 \u092E\u0941\u0916\u094D\u092F \u0930\
  \u0942\u092A \u0938\u0947 HTML \u0915\u094B \u0938\u0940\u0927\u0947 \u092A\u093E\
  \u0930\u094D\u0938 \u0915\u0930\u0928\u0947 \u0915\u0947 \u0932\u093F\u090F \u0928\
  \u0939\u0940\u0902 \u092C\u0928\u093E\u092F\u093E \u0917\u092F\u093E \u0939\u0948\
  \u0964 \u0939\u093E\u0932\u093E\u0901\u0915\u093F, \u092F\u0939 `curl`, `grep`,\
  \ `sed`, `awk` \u091C\u0948\u0938\u0947 Unix \u0914\u091C\u093E\u0930\u094B\u0902\
  \ \u0915\u094B \u090F\u0915 \u0938\u093E\u0925 \u091C\u094B\u0921\u093C\u0928\u0947\
  \ \u092F\u093E `pup` \u092F\u093E \u092A\u093E\u092F\u0925\u0928 \u0938\u094D\u0915\
  \u094D\u0930\u093F\u092A\u094D\u091F \u092E\u0947\u0902 `beautifulsoup` \u091C\u0948\
  \u0938\u0947 \u0935\u093F\u0936\u0947\u0937\u091C\u094D\u091E \u0909\u092A\u0915\
  \u0930\u0923\u094B\u0902 \u0915\u093E \u0909\u092A\u092F\u094B\u0917 \u0915\u0930\
  \u0928\u0947 \u092E\u0947\u0902 \u0909\u0924\u094D\u0915\u0943\u0937\u094D\u091F\
  \ \u0939\u0948\u0964 \u0928\u0940\u091A\u0947 \u0909\u0926\u093E\u0939\u0930\u0923\
  \u094B\u0902 \u092E\u0947\u0902 \u0926\u093F\u0916\u093E\u092F\u093E \u0917\u092F\
  \u093E \u0939\u0948 \u0915\u093F \u0915\u0948\u0938\u0947 \u092B\u093F\u0936 \u0936\
  \u0947\u0932 \u0915\u0947 \u092D\u0940\u0924\u0930 \u0938\u0947 \u0907\u0928 \u0909\
  \u092A\u0915\u0930\u0923\u094B\u0902 \u0915\u093E \u0932\u093E\u092D \u0909\u0920\
  \u093E\u0915\u0930 HTML \u0915\u094B \u092A\u093E\u0930\u094D\u0938 \u0915\u093F\
  \u092F\u093E \u091C\u093E\u090F\u0964\n\n#."
title: "HTML \u0935\u093F\u0936\u094D\u0932\u0947\u0937\u0923"
weight: 43
---

## कैसे:
फिश शेल मुख्य रूप से HTML को सीधे पार्स करने के लिए नहीं बनाया गया है। हालाँकि, यह `curl`, `grep`, `sed`, `awk` जैसे Unix औजारों को एक साथ जोड़ने या `pup` या पायथन स्क्रिप्ट में `beautifulsoup` जैसे विशेषज्ञ उपकरणों का उपयोग करने में उत्कृष्ट है। नीचे उदाहरणों में दिखाया गया है कि कैसे फिश शेल के भीतर से इन उपकरणों का लाभ उठाकर HTML को पार्स किया जाए।

### `curl` और `grep` का उपयोग करते हुए:
HTML सामग्री लाना और उन पंक्तियों को निकालना जिसमें लिंक्स होते हैं:

```fish
curl -s https://example.com | grep -oP '(?<=href=")[^"]*'
```

आउटपुट:
```
/page1.html
/page2.html
...
```

### `pup` (HTML पार्सिंग के लिए एक कमांड-लाइन टूल) का उपयोग करते हुए:
पहले, सुनिश्चित करें कि `pup` स्थापित है। फिर आप इसका उपयोग उनके टैग्स, आईडी, क्लासेज, आदि से तत्वों को निकालने के लिए कर सकते हैं।

```fish
curl -s https://example.com | pup 'a attr{href}'
```

आउटपुट, `grep` उदाहरण के समान, `<a>` टैग्स के href अट्रिब्यूट्स को सूचीबद्ध करेगा।

### पायथन स्क्रिप्ट और `beautifulsoup` के साथ:
जबकि फिश स्वयं HTML को मूल रूप से पार्स नहीं कर सकता, यह पायथन स्क्रिप्ट्स के साथ बिना किसी बाधा के एकीकृत करता है। नीचे एक संक्षिप्त उदाहरण है जो पायथन के साथ `BeautifulSoup` का उपयोग करके HTML से शीर्षकों को पार्स और निकालता है। सुनिश्चित करें कि आपके पायथन वातावरण में `beautifulsoup4` और `requests` स्थापित हैं।

**parse_html.fish**

```fish
function parse_html -a url
    python -c "
import sys
import requests
from bs4 import BeautifulSoup

response = requests.get(sys.argv[1])
soup = BeautifulSoup(response.text, 'html.parser')

titles = soup.find_all('title')

for title in titles:
    print(title.get_text())
" $url
end
```

उपयोग:

```fish
parse_html 'https://example.com'
```

आउटपुट:
```
Example Domain
```

ये प्रत्येक विधियाँ विभिन्न उपयोग के मामलों और जटिलता के पैमाने, साधारण कमांड-लाइन टेक्स्ट मैनिपुलेशन से लेकर पायथन स्क्रिप्ट्स में `beautifulsoup` की पूरी पार्सिंग शक्ति तक सेवा प्रदान करती हैं। आपकी आवश्यकताओं और HTML संरचना की जटिलता के आधार पर, आप एक सरल Unix पाइपलाइन या एक अधिक शक्तिशाली स्क्रिप्टिंग दृष्टिकोण चुन सकते हैं।
